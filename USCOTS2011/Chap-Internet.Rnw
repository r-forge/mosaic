\chapter{Taking Advantage of the Internet}


\SweaveOpts{prefix.string=figures/fig}  % location of 
\SweaveOpts{highlight=T}    % not sure this does anything unless we use pgfSweave
\SweaveOpts{tidy=F}         % keep.source probably disables this
\SweaveOpts{pdf=T}          % use pdf for graphics
\SweaveOpts{strip.white=T}  % remove blank lines at beginning and end 
\SweaveOpts{keep.source=T}  % keeps formatting from original; allows ? to work
\SweaveOpts{width=4}
\SweaveOpts{height=2}

<<setup,echo=F>>=
source('setup.R')
@ 

The Internet provides a wealth of data spanning the world, access
to sophisticated statistical computing, and a practical means for
you to communicate with your own students.  In this chapter, we'll
illustrate some mundane ways for you to distribute and share data and
software with your students, web-based interfaces for statistical
computing,  as well as tools for ``scraping'' data
from the Internet using application program interfaces (API's) or
through XML (eXtensible Markup Language).   

We draw your attention particularly to 
provocative papers by Gould \cite{Goul:2010} and Nolan and Temple Lang
\cite{nola:temp:2010}, who
highlight the importance of broadening the type of data students encounter
in their first courses as well as the role of computing in modern statistics, respectively.
\FoodForThought{The wealth of data accessible to students on the internet
continues to increase at what feels like an exponential rate}

\section{Sharing with and among your Students}

Instructors often have their own data sets to illustrate 
points of statistical interest or to make a particular connection with
a class.  Sometimes you may want your class as a whole to construct a
data set, perhaps by filling in a survey or by contributing
their own small bit of data to a class collection.  Students may be
working on projects in small groups; it's nice to have tools to
support such work so that all members of the group have access to the
data and can contribute to a written report.

There are now many technologies for supporting such sharing.  For the
sake of simplicity, we will emphasize three that we have found
particularly useful both in teaching statistics and in our
professional collaborative work.  These are:
\begin{itemize}
\item A web site with minimal overhead, such as provided by Dropbox.
\item The services of Google Docs.
\item A web-based \RStudio\ server for \R.
\end{itemize}
The first two are already widely used in university environments and
are readily accessible simply by setting accounts.  Setting up an
\RStudio\ web server requires some IT support, but is well within the
range of skills found in IT offices and even among some individual faculty.

\subsection{Your Own Web Site}

You may already have a web site.  We have in mind a place where you
can place files and have them accessed directly from the Internet.
For sharing data, it's best if this site is public, that is, it does not require a login.
That rules out most ``course support'' systems such as Moodle or
Blackboard.  

The Dropbox service for storing files in the ``cloud'' provides a very
convenient way to distribute files over the web.  (Go to
\texttt{dropbox.com} for information and to sign up for an account.)
Dropbox is routinely used to provide automated backup and coordinated
file access on multiple computers.  But the Dropbox service also
provides a {\sc Public} directory.  Any files that you place in that
directory can be accessed directly by a URL.  

To illustrate, suppose you wish to share some small (or large) data set with your
students.  You've constructed this data set in a spreadsheet and
stored it as a CSV file, let's call it ``example-A.csv''.  Move this
file into the {\sc Public} directory under Dropbox --- on most
computers Dropbox arranges things so that its directories appear
exactly like ordinary directories and you'll use the ordinary familiar
file management techniques as in Figure \ref{fig:dropbox1}.
\begin{figure}
\begin{center}
\includegraphics[width=3.5in]{images/dropbox1.png}
\end{center}
\caption{\label{fig:dropbox1} Dragging a CSV file to a Dropbox Public directory}
\end{figure}

Dropbox also makes it straightforward to construct the web-location
identifying URL for any file by using mouse-based menu commands to
place the URL into the clipboard, whence it can be copied to your
course-support software system or any other place for distribution to
students.  For a CSV file, reading the contents of the file into \R\
can be done with the \texttt{read.csv()} operator, by giving it the
quoted URL:
<<read-quoted-URL>>=
a = read.csv("http://dl.dropbox.com/u/5098197/USCOTS2011/ExampleA.csv")
@ 

\begin{figure}
\begin{center}
\includegraphics[width=4.5in]{images/dropbox2.png}
\end{center}
\caption{\label{fig:dropbox2}Getting the URL of a file in a Dropbox Public directory}
\end{figure}

This technique makes it easy to distribute data with little
advance preparation.  It's fast enough to do in the middle of a
class: the CSV file is instantly available to your students.  It can
even be edited by you (but not by your students).

The same technique can be applied to all sorts of files: for example,
\R\ workspaces or even \R\ scripts.  Of course, your students need to
use the appropriate \R\ command: \function{load()} for a workspace or
\function{source()} for a script.

It's a good idea to create a file with your course-specific \R\
scripts, adding on to it and modifying it as the course progresses.
This allows you to distribute all sorts of special-purpose functions,
letting you distribute new \R\ material to your students.  For
instance, that brilliant new ``manipulate'' idea you had at 2am can be
programmed up and put in place for your students to use the next
morning in class.  Then as you identify bugs and refine the program,
you can make the updated software immediately available to your students.

For example, in the next section of this book we will discuss reading
directly from Google Spreadsheets.  It happens that we wanted to try a
new technique but were not sure that it was worth including in the
\texttt{mosaic} package.  So, we need another way to distribute it to
you.  Use this statement:
<<>>=
source("http://dl.dropbox.com/u/5098197/USCOTS2011/USCOTS2011.R")
@ 
Among other things, the operator \texttt{readGoogleCSV()} is defined
in the script that gets sourced in by that command.  Again, you can
edit the file directly on your computer and have the results instantly
available (subject only to the several second latency of Dropbox) to
your students.  Of course, they will have to re-issue the
\function{source()} command to re-read the script.

If privacy is a concern, for instance if you want the data available
only to your students, you can effectively accomplish this 
by giving files names known only to your students, e.g.,
``Example-A78r423.csv''.  


\subsection{Google Docs}

The Dropbox technique is excellent for broadcasting: taking files you
create and distributing them in a read-only fashion to your students.
But when you want two-way or multi-way
sharing of files, other techniques are called for, such as provided by
the Google Docs service.

One figure: \includegraphics[width=3in]{images/google-spreadsheet1.png}

Then do another image showing the interface and how to name the
resulting data frame.

Outside of RStudio: the readGoogleCSV file.

Example of a project: Does the door-close button on an elevator work.

Handing in a link to the file.  Creating directories for each of your
students and having them put the files there.

Google forms.

\subsection{The \RStudio\ Web Server}




\section{Data Mining Activities}
\subsection{What percentage of Earth is Covered with Water?}
\label{sec:googleMap}
We can estimate the proportion of the world covered with water by randomly 
sampling points on the globe and inspecting them using GoogleMaps.

First, let's do a sample size computation.  Suppose we want to 
estimate (at the 95\% confidence level) this proportion with $\pm 5$\%.
There are several ways to estimate the necessary sample size, including
algebraically solving
\[
(1.96) \sqrt{ \hat p (1-\hat p) /n} = 0.05
\]
for $n$ given some estimated value of $p$.  The \function{uniroot()} function
can solve this sort of thing numerically.  Here we take an approach 
that looks at a table of values of $n$ and $\hat p$ and margin of error.
<<google-sample-size>>=
n <- seq(50,500, by=50)
p.hat <- seq(.5, .9, by=0.10)
margin_of_error <- function(n, p, conf.level=.95) { 
	-qnorm( (1-conf.level)/2) * sqrt( p * (1-p) / n ) 
}
outer(n, p.hat, margin_of_error) -> tbl
colnames(tbl) <- p.hat
rownames(tbl) <- n
tbl
@
From this it appears that a sample size of approximately 300--400 will get
us the accuracy we desire.  A class of students can easily generate
this much data in a matter of minutes if each student inspects 10--20 maps.
The example below assumes a sample size of 10 locations per student.
This can be adjusted depending on the number of students and the desiered
margin of error.

\begin{enumerate}
\item Generate 10 random locations.

<<rgeo>>=
positions <- rgeo(10); positions
@

\item
Open a GoogleMap centered at each position.

<<googleMap,eval=false>>=
googleMap(pos=positions, mark=TRUE)
@
You may need to turn off pop-up block for this to work smoothly.

\item
For each map, record whether the center is located in water or on land.  \option{mark=TRUE}
is used to place a marker at the center of the map which is helpful for locations that are close to 
the coast.  
\begin{center}
\includegraphics[width=.8\textwidth]{images/google-water1}
\end{center}
You can zoom in or out to get a better look.
\begin{center}
\includegraphics[width=.8\textwidth]{images/google-water2}
\end{center}


\item
Record your data in a GoogleForm at 

\begin{center}
\url{https://spreadsheets.google.com/viewform?formkey=dGREcUR6YjRLSWFTWVpNNXA5ZUZ1TXc6MQ}

\includegraphics[width=.4\textwidth]{images/googleForm-water}
\end{center}

For the latitude and longitude information, simply copy and paste the output of 
<<googleMap-positions,eval=false>>=
positions
@
\item
After importing the data from Google, it is simple to sum the counts across the class.

<<sum-water-setup,echo=false>>=
Water = data.frame(Water=215, Land=85)
@

<<sum-water>>=
sum(Water$Water)
sum(Water$Land)
@

Then use your favorite method of analysis, perhaps \function{binom.test()}.

<<googleMap-binom.test>>=
interval(binom.test(215,300))
@
\end{enumerate}


\subsection{Roadless America}

The \function{rgeo()} function can also sample within a latitude longitude ``rectangle".
This allows us to sample subsets of the globe.  In this activity we will estimate 
the proportion of the continental United States that is within 1 mile of a road.

\begin{enumerate}
\item
Generate a random sample of locations in a box containing the continental United States.
Some of these points may be in Canada, Mexico, an ocean or a major lake.  These 
will be discarded from our sample before making our estimate.
<<rgeo-roadless>>=
positions <- rgeo(10, lonlim=c(-125,-65), latlim=c(25,50)); positions
@

\item
Open a GoogleMap centered at each position.  This time we'll zoom in a bit and add 
a circle of radius 1 to our map.

<<googleMap-roadless,eval=false>>=
googleMap(pos=positions, mark=TRUE, zoom=12, radius=1)
@


\begin{center}
\includegraphics[width=.8\textwidth]{images/google-roadless}
\end{center}
You may need to turn off pop-up block for this to work smoothly.
\item
For each map, record whether the center is close (to a road), far (from a road), water, or foreign.
You may need to zoom in or out a bit to figure this out.

\end{enumerate}

\subsection{Variations on the Google Maps theme}

There are many other quantities one could estimate using these tools.  For example:
\begin{enumerate}
\item
What proportion of you home state is within $m$ miles of a lake?  (The choice of $m$ may depend upon
your state of interest.)
\item
Use two proportion procedures  or chi-squared tests to compare states or continents.  
Do all continents have roughly the same proportion of land withing $m$ miles of water (for some $m$)?
Are Utah and Arizona equally roadless?

\item
In more advanced classes: What is the average distance to the nearest lake (in some region)?
By using concentric circles, one could estimate this from discretized data indicating, for example,
whether the nearest lake is within 1/2 mile, between 1/2 mile and 1 mile, between 1 mile and 2 miles,
between 2 miles, and 4 miles, between 4 miles and 10 miles, or more than 10 miles away.  It may be 
interesting to discuss what sort of model should be used for distances from random locations to lakes.
(It probably isn't normally distributed.)
\authNote{Is this example too complicated?}%
\end{enumerate}

\subsection{Zillow}

Zillow.com is an online real estate database that can be used to estimate
property values using tax records, sales data, and comparable homes.  

\centerline{\includegraphics[width=3.8in]{images/zillow1.png}}

The folks who run the site have made an application programming interface (aka API) that specify 
how software programs can interface with their system.  Duncan Temple Lang has
crafted a package in R which talks to Zillow. 
This can be used to dynamically generate datasets for use in courses, after
you (and/or your students) generate a \VN{zillowId} for use with the system.
(Danny Kaplan has used {\tt cars.com} to similar ends).

\InstructorNote{While this is a cool interface, students tend to be less interested
in house prices than their instructors!}

In this section, we describe how to use Zillow to generate and analyse a
dataset comprised of comparable sites to an arbitrary house of interest.

The first step is to create a Zillow account (click on \verb!Register! on the
top right of the page at \verb!zillow.com!).  You can set up an account or register
using Facebook.

Once you have the account, log in, then click on \verb!My Zillow! at the top right.
This should display your profile (in this case, for a user named \verb!SC_z!).

\centerline{\includegraphics{images/zillow_profile.pdf}}

Next, 
open the page: \url{http://www.zillow.com/webservice/Registration.htm}.  This
is the application programming interface (API) request, which requires more information
if you are a real estate professional.  Note that there are limits on the use 
of these data, which at first glance appear to not contravene use for statistics
activities and data collection. An overview of the API and terms of use can be found
at \url{http://www.zillow.com/howto/api/APIOverview.htm}.

\centerline{\includegraphics[width=4.6in]{images/zillow_api.pdf}}

You should receive information about your Zillow ID (a character string
of letters and numbers).  

Once you've set up your Zillow account, and gotten your Zillow Id,
the next step is to install the \pkg{Zillow} package. This package is
not on CRAN, but can be obtained from Omegahat (a different repository from CRAN) using
<<zillowinst,echo=TRUE, eval=FALSE>>=
install.packages("RCurl")
install.packages("Zillow", repos="http://www.omegahat.org/R", type="source", 
  dependencies="Depends")
@

Next, you should initialize your \VN{zillowID} to the value that you 
received when you registered with {\tt Zillow.com}.
<<fakezillow>>=
zillowId = "set_to_your_zillowId"
@
<<zillowid, eval=TRUE, echo=FALSE>>=
zillowId = "X1-ZWz1bvi5ru1gqz_4srxq"  # this is Nick's, please don't share!
@

This allows you to make calls to functions such as \function{zestimate()} (which
allows you to search for information about a particular property) and
\function{getComps()} (which facilitates finding a set of comparable properties.  
Here we find information about an arbitrary house in California, as well as
comparable properties.
<<zillow1>>=
require(Zillow)
est = zestimate("1280 Monterey Avenue", "94707", zillowId)
comps = getComps(rownames(est), zillowId)
est
rownames(est)
names(comps)
@
<<zillow2>>=
table(comps$bathrooms)
table(comps$bedrooms)
fivenum(comps$finishedSqFt)
@
We can compare numerical summaries of the size of the house for houses with different 
number of bedrooms:
<<zillowfav>>=
require(Hmisc)
summary(finishedSqFt ~ bedrooms, data=comps, fun=favstats)
@
We can look at the distribution of Zillow price lower bound, upper bound, as well as assessed
(tax) value.
\InstructorNote{This syntax is somewhat dense, since the \function{bwplot()}
function is expecting a data frame, not 3 vectors}
<<zillowprices-bwplot,fig=TRUE,width=6>>=
bwplot(rep(c("Low", "Assessed", "High"), each=nrow(comps)) ~ c(low, taxAssessment, high),
  data=comps, horizontal=TRUE, xlab='value ($)')
@

It's interesting that for these properties, assessed values tend to lag far behind the lower and
upper Zillow estimates.  We could explore whether this is true in California more generally.

It's possible to plot the results of our comparable properties, which yields a scatterplot
of price by square feet (with the number of bedrooms as well as the low and high range) as
well as a scatterplot of amount/finished square feet vs log size in square feet.
<<zillowcomps,fig=TRUE,height=3.5,width=6>>=
plot(comps)
@

Several aspects of this activity are worth noting: 
\begin{enumerate}
\item There is some startup cost for instructors and students (since each user will need
their own ZillowID\footnote{By default, the number of calls per day to the API is limited to 1000,
which could easily be exceeded in a lab setting if, contrary to the terms of use, the Zillow ID
were to be shared.}).  
\item Once set up, the calls to the Zillow package are very straightforward, and provide
immediate access to a wealth of interesting data.
\item This could be used as an activity to provide descriptive analysis of comparable 
properties, or in a more elaborate manner to compare properties in different cities or
areas.
\item Since the latitude and longitude of the comparable properties is returned, users
can generate maps using the mechanisms described in \ref{sec:googleMap}.
\end{enumerate}

\subsection{Other variants}

We've outlined several approaches which efficiently scrape data from the web.
But there are lots of other examples (many due to Duncan Temple Lang) which may be worth exploring.  These include:
\begin{description}
\item[NY Times:] interface to several of the \emph{New York Times} web services
for searching articles, meta-data, user-generated content and best seller lists 
(\url{http://www.omegahat.org/RNYTimes})
\item[Flickr:] interface to the Flickr photo sharing service 
(\url{http://www.omegahat.org/Rflickr})
\item[Google Docs:] interface to allow listing documents on Google Docs along with details,
downloading contents, and uploading files (\url{http://www.omegahat.org/RGoogleDocs})

\item[Twitter:] interface to access Twitter feeds in various ways 
(\url{http://cran.r-project.org/web/packages/twitteR})
\item[last.fm:] interface to the \verb!last.fm! music recommendation site (\url{http://cran.r-project.org/web/packages/RLastFM})
\end{description}






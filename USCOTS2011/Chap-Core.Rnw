

\chapter{The Core of a Traditional Course}

\SweaveOpts{prefix.string=figures/fig}  % location of 
\SweaveOpts{highlight=F}    % not sure this does anything unless we use pgfSweave
\SweaveOpts{tidy=F}         % keep.source probably disables this
\SweaveOpts{pdf=T}          % use pdf for graphics
\SweaveOpts{strip.white=T}  % remove blank lines at beginning and end 
\SweaveOpts{keep.source=T}  % keeps formatting from original; allows ? to work
%% \SweaveOpts{eval=false}     % temporary

<<setup,echo=F>>=
source('setup.R')
@ 

In this chapter, we will briefly review the commands and functions needed
to analyze data from a more traditional introductory statistics course.
We will use data from the HELP study: a randomized trial of a novel 
way to link at-risk subjects with primary care.  More information on the
dataset can be found in section \ref{sec:help}.

Since the selection and order of topics can vary greatly from 
textbook to textbook and instructor to instructor, we have chosen to 
organize this material by the kind of data being analyzed.  This should make
it straightforward to find what you are looking for even if you present 
things in a different order.  This is also a good organizational template
to give your students to help them keep straight ``what to do when".

It's worth noting how we teach the ``Traditional Course'', which, contrary
to rumor, some of us do on occasion.  Nick has used the 5th edition of
Moore and McCabe \cite{moor:mcca:2006}, where he introduces least squares 
regression at the end of the first week of a semester, and multiple regression
(purely descriptively) at the end of the second week.  Design is the next
main topic, then a brutally pruned intro to probability and sampling distributions.
Interval estimation and testing are introduced in one or two settings, then 
the class returns to inference for multiple regression.  While students are working
on projects involving a multiple linear regression model with 2 predictors,
some categorical data analysis is covered.

\authNote{Others interested in chiming in?}

\section{One Quantitative Variable}

\subsection{Graphical and Numerical Summaries}

R includes a number of commands to numerically summarize variables.
These include the capability of calculating the mean, standard deviation,
variance, median, five number summary, intra-quartile range (IQR) as well as arbitrary quantiles.  We will
illustrate these using the CESD (Center for Epidemiologic Studies - Depression)
measure of depressive symptoms.  To improve the legibility of output,
we will also set the default number of digits to display to a more reasonable
level.

<<cesd1,cache=F>>=
options(digits=3)
mean(HELP$cesd)
sd(HELP$cesd)
sd(HELP$cesd)^2
var(HELP$cesd)
@

It is also straightforward to calculate quantiles of the distribution.

<<cesd1>>=
median(HELP$cesd)
five <- fivenum(HELP$cesd)
five     # display the object (vector of length 5)
five[4] - five[2]
IQR(HELP$cesd)
quantile(HELP$cesd)   # may differ from fivenum()
quantile(HELP$cesd, c(.25, .50))
@

We see that it is possible to interact with the objects created by these
functions to calculate the IQR (or a function can generate this directly).
By default, the 
\verb!quantile()! function displays the quartiles, but can be given
a vector of quantiles to display.

The \verb!histogram()! function is used to create a histogram.

\vspace{-8mm}
\begin{center}
<<cesd-hist,fig=TRUE,width=3,height=1.6>>=
histogram(~ cesd, HELP)
@
\end{center}

In the HELP dataset, approximately one quarter of the subjects
are female.  It is straightforward to restrict our attention to
just those subjects.

The \verb!subset()! function can generate a new data frame containing
just the women.  Once this is created, we
used the \verb!stem()! function to create a stem and leaf plot.
<<cesd-stem>>=
female <- subset(HELP, sex=='female')
stem(female$cesd)
@

The \verb!dotPlot()! function is used to create a dotplot a la Fathom.

\vspace{-8mm}
\begin{center}
<<cesd-dot,fig=TRUE,width=3,height=1.6>>=
dotPlot(~ cesd, data=female)
@
\end{center}
We could also have made our subset ``on the fly'', just for the purposes of graphing:
\begin{center}
<<cesd-dot2,fig=TRUE,width=3,height=1.6>>=
dotPlot(~ cesd, data=HELP, subset=(sex=='female'))
@
\end{center}

Or we could make side-by-side dotplots of men and women:
\begin{center}
<<cesd-dot3,fig=TRUE,width=5,height=1.9>>=
dotPlot(~cesd | sex, data=HELP)
@
\end{center}

\iffalse
Nicer if we recode:
\begin{center}
<<cesd-dot4,fig=TRUE,width=5,height=1.9>>=
HELP$sex <- factor( HELP$female, labels=c('male','female') )
dotPlot( ~ cesd | sex, data=HELP)
@
\end{center}
\fi

\subsection{Density Curves and Normal Distributions}

<<norm1,fig=TRUE,width=5,height=1.9>>=
xpnorm(1.96, 0, 1)
@

<<dens1,fig=TRUE,width=5,height=1.9>>=
densityplot(~ cesd, data=female)
@

\subsection{Power Calculations}

\authNote{NH: This is a placeholder: I'm not sure if we want this at all, or here, as the simulation
approach really belongs in Simulation}

\noindent
Let $X_1, ..., X_{25}$ be i.i.d. $N(.3, 1)$.  Consider testing the null hypothesis $H_0: \mu=0$ versus $H_A: \mu>0$ at significance level $\alpha=.05$.  Compare the power of the sign test and the power of the test based on normal theory (one sample one sided t-test) assuming that $\sigma$ is known.

\noindent
We calculate the power of the sign test as follows. The probability that $x > 0$, given that $H_A$ is true:
<<>>=
1-pnorm(0,.3,1)
@
\noindent
Using $pbinom$, we can find the rejection region and the critical value. We reject when $t < 0.05$:
<<>>=
sim=round(1-pbinom(0:25, 25, .5), 3)
lsim=length(sim[sim>0.05]);lsim
# include plot of dbinom() under null + alternative
@
\noindent
Looking at the distribution of this, we see that the rejection region is $X_i > 17$. Given that $p = .6179$, we can now find the probability that $\delta > 0$ given $H_A$:
<<>>=
powersign=1-pbinom(17, 25, .6179); powersign
@
\noindent
Thus, the power of the sign test is approximately \Sexpr{round(powersign, 4)}.

\medskip
\noindent
We then calculated the power of the test based on normal theory as follows:
First we found the rejection region.

<<>>=
# Under the null P(X>=17) = 1 - P(X<16) =
1-pbinom(16, 25, .5) # = 0.0539, our alpha level.
alpha=.0539 # alpha not wholly = 0.05 since there are only a discrete set of values.
n=25; sigma=1 # given
sediff=sqrt(2*sigma^2/n)
tstar=qnorm(1-alpha, 0, sediff) # 1-alpha = .9461
# So we're actually getting a 94.61% CI
@
Therefore, we reject for observed values greater than \Sexpr{round(tstar,3)}.  Then, to calculate the power of this one-sided test we find the area under the alternative hypothesis to the right of our t*.
<<>>=
powert=1-pnorm(tstar, .3, 1)
@
Thus, the power of the test based on normal theory is \Sexpr{round(powert,3)}.
To check this we can use the {\tt power.t.test()} in R.
<<>>=
alpha=1-pbinom(16, 25, .5)
power.t.test(n=25, delta=.3, sd=1, sig.level=alpha, alternative="one.sided",
type="one.sample")$power
@

Comparing the two methods we see that the normal theory power calculation is greater than the sign test power calculation.

We can simulate the power of the sign test for 1000 samples to verify and check our answer:
<<>>=
numsim=1000
ressign=numeric(numsim)
for (i in 1:numsim){
x=rnorm(25, 0, 1)
ressign[i]=sum(x>0)
}
powersign=sum(ressign>17)/numsim
@

The power of the sign test using a simulation is approximately \Sexpr{round(powersign,3)}. The difference between the analytic and empirical solutions is not unusual because we expect some variability with a simulation.

Similarly, we can simulate the power of the test based on normal theory for 1000 samples:
<<>>=
numsim=1000
resnorm=numeric(numsim)
for (i in 1:numsim){
x=rnorm(25, 0, 1)
resnorm[i]=t.test(x, type="one.sided")$p.value
}
powernorm=sum(resnorm<.05)/numsim
@

We find the power to be approximately \Sexpr{round(powernorm,3)}.



\section{One Categorical Variable}

\subsection{Graphical and Numerical Summaries}

<<homeless-table>>=
table(HELP$homeless)
perctable(HELP$homeless)     # display table using percentages
@

\subsection{The Binomial Test}

\subsection{The Proportion Test}

\subsection{Goodness of Fit Tests}

\subsection{Power Calculations}


\section{Two Quantitative Variables}

\subsection{Paired t}

\subsection{Scatterplots}

\subsection{Correlation}

\subsection{Simple Linear Regression}

\section{Two Categorical Variables}

\subsection{Cross classification Tables}

\subsubsection{From Raw Data}
<<homeless-sex>>=
table(HELP$homeless, HELP$female)
xtabs(~ homeless + female, HELP)     
@

\subsubsection{Building Cross Tables from Already Summarized Data}

\subsection{Chi-squared tests}

\subsubsection{Displaying additional information: \texttt{xchisq.test()}}

\subsection{Fisher's Exact Test}

\section{Quantitative Response to a Categorical Predictor}

\subsection{A Bivariate Predictor: Two-sample t}
Here we will compare the distributions of CESD scores by sex.
The \verb!HELP! data set has a numeric variable \verb!female!
that codes sex us 0 for male and 1 for female.
To ensure that the display is clearly
labeled, we first create a new factor (i.e., categorical) variable called 
\verb!gender!.

<<cesd-gender-better>>=
HELP$gender <- factor(HELP$female, labels=c('male', 'female'))
# sanity check:
xtabs( ~ female + gender, HELP)
@
As it turns out, the \verb!HELP! data set already had a recoded 
version of female called \verb!sex!.  But many data sets require this sort
of conversion from numeric codes to factors.
<<>>=
# HELP already has a factor called sex, so this was redundant effort
xtabs( ~ sex + gender, HELP)
@

The \verb!tapply()! function can be used to calculate the mean CESD score
(given as first argument)
for each of the two groups (given as second argument).  The third argument
specifies which function to run for each of these subgroups.
<<tapply>>=
tapply(HELP$cesd, HELP$sex, mean)
@

\authNote{Which method(s) do we want to show?}
Alternatives to the code above:
<<tapply-alternatives>>=
aggregate(cesd ~ sex, HELP, FUN=mean)
aggregate(cesd ~ sex, HELP, FUN=favstats)
summary(cesd ~ sex, HELP, fun=mean)
summary(cesd ~ sex, HELP, fun=favstats)
@


Boxplots are a particularly helpful graphical display to compare distributions.
The \verb!bwplot()! function can be used to display the boxplots for the CESD scores separately by sex.  We see from both the numerical and graphical
displays that women tend to have slightly higher CESD scores than men.
\authNote{Should mention use of \verb!xyplot()! when the sample sizes are small.
No reason to compute 5-number summaries of 10 or fewer numbers really.}

\vspace{-8mm}
\begin{center}
<<cesd-box,fig=TRUE,width=3,height=1.6>>=
bwplot(cesd ~ sex, data=HELP)
@
\end{center}


\subsection{1-way ANOVA}

\subsection{Tukey's Honest Significant Differences}

\section{Categorical Response to a Quantitative Predictor}

\subsection{Logistic Regression}

\section{Design and Randomization}

\section{Bias and Variability}

\section{Probability and Random Variables}

\label{sec:DiscreteDistributions}

\section{More than Two Variables}

\subsection{Two-way ANOVA}

\subsection{Multiple Regression}



\chapter{Multivariate Statistics -- Early?}

\label{chap:multivariate-early}

\SweaveOpts{prefix.string=figures/multivar}  % location of 
\SweaveOpts{highlight=T}    % not sure this does anything unless we use pgfSweave
\SweaveOpts{tidy=F}         % keep.source probably disables this
\SweaveOpts{pdf=T}          % use pdf for graphics
\SweaveOpts{strip.white=T}  % remove blank lines at beginning and end 
\SweaveOpts{keep.source=T}  % keeps formatting from original; allows ? to work

<<setup,echo=F>>=
source('setup.R')
@ 

If you are of a certain age, you may remember the 1960s television show {\em
  Lost in Space}.  One of the characters, the Robot, was often
assigned guard duty.  Robot would march back and forth, just like a
soldier on guard duty.

But why?  Soldiers are ordered to march back and forth so that they
won't fall asleep; walking forces them to maintain a certain attention
to their duty.  Robot has no such need; his sensors and circuits can reliably
detect intruders without the marching.  Of course, the television
viewers wouldn't know this about robots.  Using the robot in the
manner of a soldier was a way to introduce new technology to people
with old mind-sets.

Now fast forward from the television of the 1960s to the classroom of
the 21st century.  Students have computers.  They use statistical
software packages to do calculations.  But what calculations are they
doing?  Sample means, sample proportions, differences between means.

This Robot walking back and forth.  A way to use new technology with
old mind-sets.  But it's the professors, not the students, with the
old mind-sets.  The students are open to new things.  They don't need
to know that, once upon a time, it was a feat to get a machine to add
up a column of numbers.

We professors were educated at a time when the tools for inverting a
matrix were paper and pencil, when doing least squares problem involved
a strange thing called a ``pseudo-inverse'' that you might learn in
your fourth or fifth semester of university-level mathematics.  But, now, least squares
problems are no more difficult or time consuming to the human than
square roots or addition.  We just have to learn to use the tools in
the right way.  

Or, rather, we have to show our students what are the
basic operations that are important for statistical reasoning in an
age of modern computation.  Not marching back and forth, like robot
soldiers, computing sums of columns of numbers, but thinking about how to model the
potentially rich interplay among multiple variables.

The standard approach to introductory statistics is based on a few
simple operations: adding, squaring/square-rooting to finding means and standard deviations; counting to
find proportions and medians/quantiles.  These operations are
(supposed to be) familiar to students from high-school mathematics.

Here we'll examine the consequences of adding in a new basic operation
that is not in the traditional high-school curriculum, but which is
actually quite consistent with the ``Common Core'' curriculum being
introduced by many U.S. states.\cite{common-core-2010}


The operation is fitting multivariate linear models.  Modern software
makes it no more arduous than finding a mean or standard deviation.
Our emphasis here will be on how to introduce the conceptual
foundations --- using just high-school math and simple extensions
largely specified already in the ``Common Core'' --- that make the concept
of modeling accessible.

\section{The Mathematical Foundations}

A standard part of the high-school curriculum is the equation of a
straight line: $y = m x + b$.  Many students will recognize that $m$
is a slope and $b$ is the $y$-intercept.  

It's helpful to move them a bit beyond this:
\begin{itemize}
\item Emphasize the ``function'' concept.  A function, of course, is a
  relationship between an input and an output.  Generalize this, so
  that students are comfortable with using names other than $x$ as the
  input and
  $y$ as the output.  For example, 
  $$\mbox{height} = f( \mbox{age} ) = 3\ \mbox{age} + 20$$.
  
\item Introduce the idea of functions of non-numeric variables, for example:
$$\mbox{height} = g( \mbox{sex} ) = \left\{ \begin{array}{ll}
      67 & \mbox{for sex $=$ female}\\
      71 & \mbox{for sex $=$ male}\\
      \end{array}\right.$$
   
\item Generalize the idea of a function to include having more than
  one input, for instance

$$\mbox{height} = h( \mbox{age}, \mbox{sex} ) = -2\ \mbox{age} + 
      \left\{ \begin{array}{ll}
      67 & \mbox{for sex $=$ female}\\
      71 & \mbox{for sex $=$ male}\\
      \end{array}\right.$$

\item  De-program your students from thinking that there is one, and
  only one, correct formula for a relationship.  Introduce the idea of a function as a
  description of a relationship and that there can be different descriptions of the same
  relationship, all of which can be right in some ways.  Different
  descriptions can include some details and exclude others. Such
  descriptions are called ``models.''  The above models
  $f(\mbox{age})$, and $g(\mbox{sex})$ and $h(\mbox{age}, \mbox{sex})$
  give different outputs for the same inputs.  For example, for a male
  of age 10, according to the models, the height is variously $f(10) =
  50$ or $g(\mbox{male}) = 71$ or $h(10, \mbox{male}) = 51$.
  
\item  Many useful models don't give exactly the right output for
  every case.  Not every 10-year old male has the same height.  The
  difference between what a model says, and what the value is for an
  actual case, will not in general be zero.  The ``residual'' is the difference between
  the actual value for a given 10-year old male, say Ralph, and what
  a given model says about 10-year old males in general.  The
  residuals give important information about how good a model is.
   
\end{itemize}


\section{The Language of Models}

There is a language for defining models that is different from
writing down an algebraic formula.  

You have already seen some aspects of this notation in graphics
commands, e.g. verb+height ~ sex+.  You can read this in any of several
ways:
\begin{itemize}
  \item Break down \VN{height} by \VN{sex} (as in a boxplot)
  \item \VN{height} versus \VN{sex}
  \item Model \VN{height} as a function of \VN{sex}.  
\end{itemize}
In this section, you'll see more complicated models, involving
multiple variables.  This makes it worthwhile to assign more precise
labels to the different components of the modeling language, which
has just a few components:
\begin{itemize}
  \item The response variable.  This is the output of the model function,
    \VN{height} in the above examples.
  \item The explanatory variables.  These are the inputs to the
    model function: \VN{age} and \VN{sex} in the above examples.
  \item Model terms.  Examples of model terms are explanatory
    variables themselves and a special term called the ``intercept.''
    There are a few others, but we'll deal with them as we come to them.
\end{itemize}
(A more comprehensive introduction is given in Chapters 4 and 5 of \cite{kaplan-2009-book}.)


As an example, consider this simple formula:
$$ z = 7 + 3 x + 4.5 y.$$
The corresponding model description consists of the response variable
$z$, and three model terms: the explanatory variables $x$ and
$y$ and the intercept term.  In the modeling language, it would be written:
\begin{quotation}
\centerline{\model{z}{1 + x + y}}
\end{quotation}
Notice that instead of the $=$ sign, we are using the $\sim$ sign.
Also, notice that the specific coefficients $7$, $3$, and $4.5$ are
missing.  The model description is a kind of skeleton for describing
the shape of the model.  It's like saying: ``We want a straight line
model,'' rather than giving the complete specification of the formula.

The process of finding a specific formula to make a model match the
pattern shown by data is called ``fitting the model to the data.''  

To see how different model specifications correspond to different
``shapes'' of models, consider the following data of world-record
times in the 100-meter free-style race.

<<read-swim,echo=false>>=
swim = read.csv("http://www.macalester.edu/~kaplan/ISM/datasets/swim100m.csv")
swim.plot = function(col='black',show.legend=TRUE,...){
plot( time ~ year, pch=21-2*as.numeric(sex), cex=1.4,xlim=c(1899,2010),
     cex.lab=1.3, cex.axis=1.3,data=swim,xlab='Year',
     ylab='Time (secs)',col=col,...)
  if( show.legend) legend(1980,92, legend=c("Women","Men"),pch=c(19,17),cex=1.3)
}
@ 


<<swim-data-raw,fig=true,pdf=true,include=true,width=6,height=4,echo=false>>=
swim.plot( )
@ 


You can see the steady improvement in records over the decades from
1900 to the present.  Men's times are somewhat faster than women's.

Now to build some models.

\subsection{\model{\VN{Time}}{1 + \VN{Year}}}

The model \model{\VN{time}}{1 + \VN{year}} gives the familiar
straight-line form: the intercept term (written simply as 1) and a term corresponding to the
linear dependence on \VN{year}.

<<swim-data-1,fig=true,pdf=true,include=true,width=6,height=4,echo=false>>=
swim.mod.plot = function(form,dots=FALSE, lwd=4) {
  t = as.character(form)
  t = paste(t[c(2,1,3)],collapse=" ")
  foo = lm( form, dat=swim)
  swim.plot(col='gray', show.legend=FALSE,
            main=t)
  if (dots)
      points( foo$fitted ~ swim$year, pch=20, cex=1.7,col='black')
  else 
      abline(foo$coef, lwd=lwd)
}
swim.mod.plot(time ~ year)
@ 

This model captures some of the pattern evident in the data: that
swimming times are improving (getting shorter) over the years.  And it
ignores other obvious features, for example the difference between men's
and women's times, or the curvature reflecting that records are not
improving as fast as they did in the early days.


\subsection{\model{\VN{Time}}{\VN{Sex}}}

The model \model{\VN{time}}{\VN{sex}} breaks down the swimming times
according to \VN{sex}:

<<swim-data-2,fig=true,pdf=true,include=true,width=6,height=4,echo=false>>=
swim.mod.plot(time ~ sex, dots=TRUE)
@ 

This model reflects the typical difference between men's and women's
times.  It's oblivious to the trend that records improve over the
years.  Why?  Because the variable \VN{year} was not included in the model.

\subsection{\model{\VN{Time}}{\VN{Sex}+\VN{Year}}}

The record time evidently depends both on \VN{sex} and \VN{year}, so
it's sensible to include both variables in the model

<<swim-data-3,fig=true,pdf=true,include=true,width=6,height=4,echo=false>>=
swim.mod.plot(time ~ sex + year, dots=TRUE)
@ 

\authNote{DTK: Should these graphics be re-written to display as
  continuous forms rather than dots?}

This is a straight-line model with separate lines for the different
sexes. The intercept is different for the different sexes, but the
slope is the same.  
This model is able to reflect both the typical reflects the typical difference between men's and women's
times.  

Students sometimes observe that the function generated by fitting this
model doesn't respect the ``vertical line test'' taught in high-school
algebra.  This is a good time to remind students that this is a
function of \emph{two} variables.  It is indeed a function, and for
any specific value of the inputs \VN{sex} and \VN{year} gives a single value.

\subsection{\model{\VN{Time}}{\VN{Sex}+\VN{Year} + \VN{Sex}:\VN{Year}}}
 
There are two ways that the previous model, \model{\VN{time}}{\VN{sex}+\VN{year}},  misses obvious features in the
data: there is no curvature over the years and the slopes are exactly
the same for men and women.  To construct a model with different
slopes for men and women requires that we add a term that combines
both \VN{sex} and \VN{year}.  Such a term is constructed with the syntax
\VN{sex}:\VN{year} (or, what would amount to the same thing,
\VN{year}:\VN{sex}).  

<<swim-data-4,fig=true,pdf=true,include=true,width=6,height=4,echo=false>>=
swim.mod.plot(time ~ sex * year, dots=TRUE)
@ 

In statistics, such a term is called an \emph{interaction term}.  (In
mathematics, it's often called a \emph{bi-linear term}.)  It's the
term that lets you have different slopes for the different sexes.  

The new phrase ``interaction term'' creates a need for a retronym, a way
to refer to those simple, non-interaction terms that we started with,
like \VN{sex} and \VN{year}.  (Common retronyms in everyday life are acoustic guitar, snail-mail, 
World War I, cloth diaper, and whole milk, compound terms that weren't needed
until electric guitars, e-mail, disposable diapers, and skim milk were
introduced, and World War II showed that the ``War to End All Wars''
was mis-named.)

The standard terminology for terms like \VN{sex} and \VN{year} is unfortunate: ``main effect.'' 
It suggests that interaction terms play a lesser role in modeling.  This is a bad
attitude, since sometimes the interaction is exactly what you're
interested in, but the terminology seems enshrined by statistical tradition.

Very often when you are including an interaction term, you want to
include the main effects as well.  There is a convenient shorthand for
this: \model{\VN{time}}{\VN{sex}*\VN{year}}

\subsection{The Intercept Only: \model{\VN{Time}}{1}}

It's also possible to have models that have no explanatory variables
whatsoever.  Just the intercept term appears to the right of the
modeling $\sim$.

<<swim-data-5,fig=true,pdf=true,include=true,width=6,height=4,echo=false>>=
swim.mod.plot(time ~ 1, dots=TRUE)
@ 

As you might expect, by leaving out both \VN{sex} and \VN{year} from
the model, it doesn't reflect the role of either variable in any way.
But the model \model{\VN{time}}{1} does get one thing very well: the
typical record time.  

Think of \model{\VN{time}}{1} as saying ``all the cases are the
same.''  In some ways, it's analogous to the model
\model{\VN{time}}{\VN{sex}}.  That model says that ``all men are the
same, and all women are the same.''  To the difference between 
\model{\VN{time}}{1} and \model{\VN{time}}{\VN{sex}} is just like the
difference between a ``grand mean'' and a ``group mean.''

\subsection{Transformation Terms}

You can construct more complicated models by adding in more
explanatory variables. (Improved swimming gear?  Better training?
Refinements in technique?).  You can also add in additional terms with
more structure.  There is a rich variety of ways to do this.

Since many students are familiar (or at least remember vaguely) the
idea of quadratics and polynomials, they might be interested to see
that the modeling language can handle this.  Here are three different
models involving a polynomial dependence on \VN{year}:

<<swim-data-6,fig=true,pdf=true,include=true,width=6,height=4,echo=false>>=
swim.mod.plot(time ~ poly(year,2), dots=TRUE)
@ 

<<swim-data-7,fig=true,pdf=true,include=true,width=6,height=4,echo=false>>=
swim.mod.plot(time ~ sex + poly(year,2), dots=TRUE)
@ 

<<swim-data-8,fig=true,pdf=true,include=true,width=6,height=4,echo=false>>=
swim.mod.plot(time ~ sex * poly(year,2), dots=TRUE)
@ 

Although these models reflect more ``detail'' in the data, namely the
curvature, they do it in a way that ultimately does not make sense in
terms of the ``physics'' of world records.
Notice how the upward facing parabolas eventually produce a pattern
where the record times increase over the years.  

There are other sorts of nonlinear terms that might be more
appropriate for modeling this sort of data.  Exponentials, square
roots, etc., even piecewise linear or bent-line forms are all
possible within the modeling framework.  


\begin{problem}
{\bf DRAFT Outline} for a swim-data modeling problem: construct a post-war
variable and add it in.  Several ways to do this: explore which one's give
models that are most satisfactory to you:
\begin{itemize}
  \item postwar = year $>$ 1945
  \item interaction with postwar and year.
  \item pmax(year - 1945, 0)
\end{itemize}
\end{problem}





\section{Finding Formulas from Data}

How to fit.

Fitted model values.

Residuals

Predict

\section{Example: Genetics before Genes}

About Galton's data.

\section{Bias in Sampling?  Choosing library books off a shelf?}

\section{Taking Your Class for a Random Walk}

\section{Biostatistics example: gene sequencing?}

\section{The perils of multiple comparisons}

\section{The sampling distribution of R2 and F under the null hypothesis}

\section{A demonstration of shuffling and how it implements the null hypothesis}

\section{Working through an ANOVA calculation by hand}

\section{Sampling bias in survival studies (with a simulation)}

\shipoutProblems

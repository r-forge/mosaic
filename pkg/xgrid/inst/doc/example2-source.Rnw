\documentclass[11pt]{article}
\usepackage{graphicx, amsmath, amsfonts, amssymb, epstopdf, color, url, hyperref} 
\usepackage[margin=1in]{geometry}
\usepackage[parfill]{parskip}
\definecolor{green}{RGB}{0,127,0}
\hypersetup{pdftitle={Fitting Latent Class Models}, colorlinks=true, linkcolor=black, citecolor=black}
\usepackage[bottom]{footmisc}
\usepackage[round]{natbib}
\bibliographystyle{abbrvnat}


% counteract the extra space created
\renewcommand*{\refname}{\vspace*{-12mm}\section{Bibliography}}

\newcommand{\file}[1]{{`\normalfont\textsf{#1}'}}

\begin{document}

\frenchspacing{}

\title{Example 2: Fitting Latent Class Models Using Add-on Packages}
\author{Sarah C. Anoke, Nicholas J. Horton\thanks{Corresponding author: nhorton@smith.edu}, Yuting Zhao \\ Department of Mathematics and Statistics \\ Smith College}
\date{\today}

\maketitle

\tableofcontents

<<hiddenOps, echo=F>>=
setwd("."); options(width=100, continue=" ")
@

\section{Introduction}
Many scientific computations can be sped up by dividing them into smaller tasks and distributing the computations to multiple systems for simultaneous processing. Such a process is referred to as {\em parallel computing}. When performed on existing grids of computers, this method can dramatically increase computation speed. Several solutions exist to facilitate this type of computation within R, and we describe one such solution here, that involves using the Apple Xgrid \citep{AppleXgridSystem}, a parallel computing environment. 

We created the {\bf xgrid} package to provide a simple interface to this distributed computing system \citep{ourpaper}. The package facilitates use of an Apple Xgrid for distributed processing of a job with many independent repetitions, by simplifying task submission (or {\em gridstuffing}) and collation of results. 

We demonstrate use of our package in the context of a real statistical problem. This example is representative of what might be encountered in the field, as it involves simulations that would ordinarily take days to complete. It involves study of the properties of latent class models, which are used to determine better schemes for classification of eating disorders \citep{keel}. The development of an empirically-created eating disorder classification system is of public health interest as it may help identify individuals who would benefit from diagnosis and treatment.

\section{Latent Class Analysis}

As described by \citet{collinslanza}, LCA is used to identify subgroups in a population. There are several criteria used to evaluate the fit of a given model, including the Akaike Information Criterion (AIC), the Bayesian Information Criterion (BIC), the Consistent Akaike Information Criterion (cAIC), and the Sample Size Adjusted Bayesian Information Criterion (aBIC). These criteria are useful, but further guidance is needed for researchers to choose between them, as well as better understand how their accuracy is affected by methodological factors encountered in eating disorder classification research, such as unbalanced class size, sample size, missing data, and under- or overspecification of the model. \citet{swanson} undertook a comprehensive review of these model criteria, including a full simulation study to generate hypothetical datasets and investigate how each criterion behaved in a variety of statistical environments. In this example, we replicate some these results using an Apple Xgrid to grid to speed up computation time.

\section{Using the Grid for a Simulation Study}

Following the approach of \citet{swanson}, we generated ``true models'' where there was an arbitrary 4-class structure, with balanced number of observations in each class. This structure was composed of 10 binary indicators in a simulated dataset of size 300. The model was fit using the {\tt poLCA()} function in the {\bf poLCA} (polytomous latent class analysis) package \citep{poLCA}. 
Separate latent class models were fit specifying the number of classes, ranging from 2 to 6.  
For each simulation, we determined the lowest values of BIC, AIC,
cAIC and aBIC and recorded the class structure associated with each value.  

Swanson and colleagues found that for this set of parameter values,
the AIC and aBIC picked the correct number of classes more than half the
time (see Table \ref{tab:poLCAresults}).

\begin{table}[tbhp]
\begin{center}
\begin{tabular}{|p{5.5cm}|l||r|r|r|r|r|} \hline
 && \multicolumn{5}{c|}{Class} \\ \hline
Criteria & Acronym &  2  &  3  &  {\bf 4}  &  5  &  6+  \\ \hline  \hline
Bayesian Information Criterion & BIC & 49\% & 44\% & {\bf 7\%} & \ 0\% & \ 0\% \\ \hline
Akaike Information Criterion &AIC & \ 0\% & \ 0\% & {\bf 53\%} & 31\% & 16\% \\ \hline
Consistent Akaike Information Criterion &cAIC & 73\% & 25\% & {\bf 2\%} & \ 0\% & \ 0\% \\ \hline
Sample Size Adjusted Bayesian Information Criterion &aBIC & \ 0\% & \ 5\% & {\bf 87\%} & \ 6\% & \ 2\% \\ \hline
\end{tabular}
\end{center}
\caption{Percentage of times (out of 100 simulations) that a particular number of classes was selected as the best model (where the true data derive 
from 4 distinct classes), when {\tt n=300}, reprinted from \citet{swanson}.  Note that a perfect criterion would have 100\% under class 4.}
\label{tab:poLCAresults}
\end{table}

This example illustrates the computational burden of undertaking simulation studies to assess the performance of modern statistical methods, as several minutes are needed to undertake each of the single iterations of the simulation (which may explain why Swanson and colleagues only fit 100 simulations for each of their scenarios).  
   
\subsection{Directory Structure}

Our first step is to set up a directory structure for our simulation (see Figure \ref{fig:input2}). 

\begin{figure}[h!]
   \begin{center}
      \includegraphics[width=0.5\textwidth]{directorystructure.pdf} 
      \caption{File structure to access the grid}
      \label{fig:input2}
   \end{center}
\end{figure}

The first item is the directory \file{input}, which contains two files that will be run on the remote agents. The first of these files, \file{job.R} (Figures \ref{code:job.R1} and \ref{code:job.R2}), defines the code to run a particular job. In this case, \file{job.R} defines two functions. The function {\tt datagen()} generates a 4-class data set. The sample size of this data set is specified by the argument {\tt samplesize} and the number of indicators is specified by {\tt dim}. The function {\tt job()} takes six arguments: {\tt param} specifies the sample size of the data set; {\tt smallclass} and {\tt largeclass} define the range of class structures; {\tt dim} specifies the number of indicators; {\tt nrep} defines the number of times the poLCA model is estimated for each data set; and {\tt ntask} specifies how many tasks to run within each job. The function {\tt job()} calls {\tt datagen()} to generate a data set, and fits a model to these data using {\tt poLCA()}. It returns a data frame containing the class structure (within the range of {\tt smallclass} and {\tt largeclass}) predicted by each information criterion (BIC, AIC, cAIC and aBIC).  

\begin{figure}[h!]
<<datagenDef>>=
# code adapted from Swanson et al. (2011)
library(scatterplot3d, lib.loc="./input/rlibs")
library(poLCA, lib.loc="./input/rlibs")

# generates data set of size 'samplesize'
# and 'dim' indicators
# with a predefined class structure
datagen = function(samplesize=300, dim=10) {
  if(samplesize %% 4 == 0) {
    subset = samplesize / 4
  } else {
    cat("Error: samplesize must be divisible by the number of classes 4.")
  }
  
  # predetermining the 4-class structure
  # values from Swanson et al. (2011)
  class1 = c(1.45, -3.48,  0.04,  1.05, -0.49, 
           	-1.10, -2.44, -1.99, -2.75, -3.48)
  class2 = c(-0.1,  1.38,  1.00,  1.06,  1.28, 
             0.48,  0.66,  0.43,  0.87,  0.16)
  class3 = c(1.28, -0.07, -0.45, -1.06,  0.19, 
             1.19, -0.83,  0.91, -1.12,  2.00)
  class4 = c(   0, -2.00, -1.69,  0.31,     0, 
             -0.58, 1.06, -1.51, -2.00,  0.63)
  type1 = exp(class1) / (1 + exp(class1))
  type2 = exp(class2) / (1 + exp(class2))
  type3 = exp(class3) / (1 + exp(class3))
  type4 = exp(class4) / (1 + exp(class4))

  x = matrix(runif(samplesize * dim), samplesize)
  x[(0 * subset + 1) : (1 * subset),] = 
    t(t(x[(0 * subset + 1) : (1 * subset),]) < type1) * 1
  x[(1 * subset + 1) : (2 * subset),] = 
    t(t(x[(1 * subset + 1) : (2 * subset),]) < type2) * 1
  x[(2 * subset + 1) : (3 * subset),] = 
    t(t(x[(2 * subset + 1) : (3 * subset),]) < type3) * 1
  x[(3 * subset + 1) : (4 * subset),] = 
    t(t(x[(3 * subset + 1) : (4 * subset),]) < type4) * 1
  ds = as.data.frame(x + 1)
  return(ds)
}
@
\caption{Contents of \file{job.R}, part 1 -- the function {\tt datagen()}. This code, as well as that of Figure \ref{code:job.R2}, should be in one file entitled \file{job.R}.}
\label{code:job.R1}
\end{figure}

\begin{figure}[h!]
<<jobDef>>=
job = function(ntask, param, dim=10, smallclass=2, largeclass=6, nrep=100) {
  diff = largeclass - smallclass + 1
  f = cbind(V1,V2,V3,V4,V5,V6,V7,V8,V9,V10) ~ 1 #LCA formula
  allbic  = rep(0, ntask)
  allaic  = rep(0, ntask)
  allcaic = rep(0,ntask)
  allabic = rep(0,ntask)
  bicmat  = matrix(nrow=ntask, ncol=diff)
  aicmat  = matrix(nrow=ntask, ncol=diff)
  caicmat = matrix(nrow=ntask, ncol=diff)
  abicmat = matrix(nrow=ntask, ncol=diff) 
  
  for (j in 1:ntask) {
    ds = datagen(samplesize=as.numeric(param), dim=dim)  
    bic  = rep(0,diff)
    aic  = rep(0,diff)
    caic = rep(0,diff)
    abic = rep(0,diff)
    
    for (i in smallclass:largeclass) {
      lc = poLCA(f, data=ds, nclass=i, graphs=FALSE, verbose=FALSE, nrep=nrep)
      bic[i-1]  = lc$bic
      aic[i-1]  = -2 * lc$llik + 2 * lc$npar
      caic[i-1] = -2 * lc$llik + lc$npar * log(lc$N) + 1
      abic[i-1] = -2 * lc$llik + lc$npar * log((lc$N + 2) / 24)
    }
    
    bicmat[j,] = bic
    minbic = which.min(bic) + 1
    allbic[j] = minbic
    aicmat[j,] = aic
    minaic = which.min(aic) + 1
    allaic[j] = minaic
    caicmat[j,] = caic
    mincaic = which.min(caic) + 1
    allcaic[j] = mincaic
    abicmat[j,] = abic
    minabic = which.min(abic) + 1
    allabic[j] = minabic
  } 
  rowname = rep(param, ntask)
  res = data.frame(samplesize=rowname, bic=allbic, aic=allaic, 
                   caic=allcaic, abic=allabic)
  return(res)
}
@
\caption{Contents of \file{job.R}, part 2 -- the function {\tt job()}. This code, as well as that of Figure \ref{code:job.R1}, should be in one file entitled \file{job.R}.}
\label{code:job.R2}
\end{figure}

The folder \file{input} also contains \file{runjob.R} (Figure \ref{code:runjob.R}), which retrieves 
and stores command line arguments from the controller, and passes them to 
{\tt job()}. The results from the completed job are saved as {\tt res0}, which is 
subsequently saved to the \file{output} folder. 

\begin{figure}[h!]
<<runjobR, eval=F>>=
source("job.R")
# processargs is expecting three arguments:
# 1) number of tasks to run within this job
# 2) parameter to pass to the function
# 3) place to stash the results when finished
processargs = function() {
  args = commandArgs(trailingOnly=TRUE)
  cat("args=", args)
  return(list(ntask=as.numeric(args[1]), param=args[2],
    resfile=args[3]))
}
arg = processargs()
res0 = job(arg$ntask, param=arg$param)
# stash the results
saveRDS(res0, file=arg$resfile)
@
\caption{Contents of \file{runjob.R}}
\label{code:runjob.R}
\end{figure}

The folder \file{output} will contain results from the simulations. After the completion of each job, the results are saved to a file in this directory. If this directory is created manually, it should be empty. If not created manually, {\tt xgrid()} will create it.

The next item in the directory structure is \file{simulation.R} (Figure \ref{code:simulation.R}), which contains the R script run on the client machine that calls {\tt xgrid()}. This function submits the simulation 
to the grid for calculation. Because this script is just an example of how to call {\tt xgrid()} and manipulate the resulting object, it can be run the way one typically submits commands during an R session. Results from all jobs are returned as one object, {\tt res}.

\begin{figure}[h!]
<<simulation, eval=F>>=
library(xgrid); library(poLCA)
# run the simulation
res = xgrid(grid="Burton-303-iMac", Rcmd="runjob.R", param=300,
            numsim=20, ntask=1)
@
\caption{Contents of \file{simulation.R}}
\label{code:simulation.R}
\end{figure} 

\subsection{Retrieval and Analysis of Results}
Figures \ref{code:expectedOutput1} and \ref{code:expectedOutput2} together demonstrate an example of what to expect before and after completing all simulations. 

\begin{figure}[h!]
<<listingResults1>>=
list.files()
list.files("input")
library(xgrid); library(poLCA)
res = xgrid(grid="Burton-303-iMac", Rcmd="runjob.R", param=300,
            numsim=20, ntask=1)
dim(res)
apply(res, 2, table)
@ 
\caption{Expected console output, part 1 -- before and after calling {\tt xgrid()} (see Figure \ref{code:expectedOutput2} for part 2)}
\label{code:expectedOutput1}
\end{figure}

\begin{figure}[h!]
<<listingResults2>>=
list.files()
list.files("output")
@
\caption{Expected console output, part 2 -- results after calling {\tt xgrid()} (see Figure \ref{code:expectedOutput1} for part 1). Note that files \file{job.err} and \file{job.out} are output files unnecessary for the interpretation of results, but listed here for completeness.}
\label{code:expectedOutput2}
\end{figure}

At the beginning of Figure \ref{code:expectedOutput1}, we see the expected directory structure. We then call {\tt xgrid()} to send {\tt numsim=20} simulations to the grid for calculation. After the completion of the entire simulation study, results from all {\tt numsim} simulations are collated and returned by the {\tt xgrid()} function as the object {\tt res}. This object is also saved as the file \file{RESULTS.rda} at the top of the directory structure (as seen in Figure \ref{code:expectedOutput2}). 

Figure \ref{code:expectedOutput2} also displays an example of what would be seen in the \file{output} folder. As expected, there are twenty files of the form \file{RESULT-1000\#}, which contain the results from each individual job. The second set of twenty files (e.g. \file{runjob.RRESULT-1000\#.Rout}) contain the code that was run to generate the corresponding result file. 

In this example, {\tt res} is a data frame with {\tt numsim} rows (one row for each simulation) and five columns (as defined in the {\tt return} statement of \file{job.R}). In Figure \ref{code:expectedOutput1}, we list the dimensions of {\tt res} and summarize the results using {\tt apply()}. 

The output generated by {\tt apply()} is also as expected. For {\tt res\$samplesize}, we see that the value {\tt 200} appears {\tt 20} times, once for each simulation. The information criterion {\tt bic} chose a 2-class structure 13 times and a 3 class structure 7 times -- reasonably close to what we'd expect based on the results of \citet{swanson}. (Table \ref{tab:poLCAresults}).

\section{Installation of Add-On Packages}
A complication of this example is that fitting latent class models in R requires the use of add-on packages. If the user of the grid has administrative privileges on the individual machines, any needed packages can be installed in the usual manner. However, if no administrative access
is available, it is possible to utilize such packages
within this setup by manually installing them in the \file{input/rlibs} 
directory and loading them within a given job. In this example, we use the {\bf poLCA} (polytomous latent class analysis) package and its supporting packages (e.g. {\bf scatterplot3d}, {\bf MASS}) with the Apple Xgrid to conduct our simulation. Below we enumerate how to make an individual package available to a job running on a given agent. 

\begin{description} 
\item[Download] the appropriate distribution file from CRAN. This file will end in {\tt .tar.gz}, which denotes a compressed archive file. 
\item[Install] the distribution file into the directory \file{input/rlibs}. This can be done using the command {\tt tar zxf poLCA\_1.3.1.tgz} or its equivalent command {\tt R CMD INSTALL poLCA\_1.3.1.tgz -l input/rlibs}.
\item[Access] the add-on package within a job running on an agent. This is done by using the {\tt lib.loc} option within the standard invocation of {\tt library}. For instance, the command {\tt library(poLCA, lib.loc="./rlibs")} was used in this example. 
\end{description}

It should be noted that the package will need to shipped over to the agent
for each job, which may be less efficient than installing the package once per agent in the usual manner (but the latter option may not be available unless the grid user has administrative access to the individual agents).

\section{Acknowledgement} 

This material is based in part upon work supported by the National Institute of Mental Health (5R01MH087786-02) and the US National Science Foundation (DUE-0920350, DMS-0721661, and DMS-0602110).

\begin{thebibliography}{5}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Apple(2009)]{AppleXgridSystem}
Apple.
\newblock \emph{Mac OS X Server: Xgrid Administration and High Performance
  Computing (Version 10.6 Snow Leopard)}.
\newblock Apple Inc, 2009.

\bibitem[Collins and Lanza(2009)]{collinslanza}
L.~M. Collins and S.~T. Lanza.
\newblock \emph{Latent Class and Latent Transition Analysis: With Applications
  in the Social, Behavioral, and Health Sciences}.
\newblock Wiley, 2009.

\bibitem[Horton et~al.(2011)Horton, Anoke, Zhao, and Jaeger]{ourpaper}
N.~J. Horton, S.~C. Anoke, Y.~Zhao, and H.~Jaeger.
\newblock Xgrid and {R}: Parallel distributed processing using heterogeneous
  groups of {A}pple computers.
\newblock \emph{In revision}, 2011.

\bibitem[Linzer and Lewis(2011)]{poLCA}
D.~A. Linzer and J.~B. Lewis.
\newblock {poLCA}: An {R} package for polytomous variable latent class
  analysis.
\newblock \emph{Journal of Statistical Software}, 42\penalty0 (10):\penalty0
  1--29, 2011.
\newblock URL \url{http://www.jstatsoft.org/v42/i10/}.

\bibitem[Keel et~al.(2004)Keel, Fichter, Quadflieg, Bulik, Baxter, Thornton,
  Halmi, Kaplan, Strober, Woodside, Crow, Mitchell, Rotondo, Mauri, Cassano,
  Treasure, Goldman, Berrettini, and Kaye]{keel}
P.~K. Keel, M.~Fichter, N.~Quadflieg, C.~M. Bulik, M.~G. Baxter, L.~Thornton,
  K.~A. Halmi, A.~S. Kaplan, M.~Strober, D.~B. Woodside, S.~J. Crow, J.~E.
  Mitchell, A.~Rotondo, M.~Mauri, G.~Cassano, J.~Treasure, D.~Goldman, W.~H.
  Berrettini, and W.~H. Kaye.
\newblock Application of a latent class analysis to empirically define eating
  disorder phenotypes.
\newblock \emph{Archives of General Psychiatry}, 61\penalty0 (2):\penalty0
  192--200, February 2004.

\bibitem[Swanson et~al.(2011)Swanson, Lindenberg, Bauer, and Crosby]{swanson}
S.~A. Swanson, K.~Lindenberg, S.~Bauer, and R.~D. Crosby.
\newblock A {Monte Carlo} investigation of factors influencing latent class
  analysis: An application to eating disorder research.
\newblock \emph{International Journal of Eating Disorders}, 2011.

\end{thebibliography}


\nonfrenchspacing

\end{document} 
\documentclass[11pt]{article}
\usepackage{graphicx, amsmath, amsfonts, amssymb, epstopdf, color, url, hyperref} 
\usepackage[margin=1in]{geometry}
\usepackage[parfill]{parskip}
\definecolor{green}{RGB}{0,127,0}
\hypersetup{pdftitle={Assessing robustness of t-test}, colorlinks=true, linkcolor=black, citecolor=black}
\usepackage[bottom]{footmisc}
\usepackage[round]{natbib}
\bibliographystyle{abbrvnat}

% counteract the extra space created
\renewcommand*{\refname}{\vspace*{-12mm}\section{Bibliography}}

\newcommand{\file}[1]{{`\normalfont\textsf{#1}'}}

\begin{document}

\frenchspacing{}

\title{Example 1: Assessing the Robustness of the One-Sample t-test}
\author{Sarah C. Anoke, Nicholas J. Horton\thanks{Corresponding author: nhorton@smith.edu}, Yuting Zhao \\ Department of Mathematics and Statistics \\ Smith College}
\date{\today}

\maketitle

\tableofcontents

<<hiddenOps, echo=F>>=
setwd("."); options(width=100, continue=" ")
@

\section{Introduction}

Many scientific computations can be sped up by dividing them into smaller tasks and distributing the computations to multiple systems for simultaneous processing. Such a process is referred to as {\em parallel computing}. When performed on existing grids of computers, this method can dramatically decrease computation time. Several solutions exist to facilitate this type of computation within R, and we describe one such solution here, that involves using the Apple Xgrid \citep{AppleXgridSystem}, a parallel computing environment. 

We created the {\bf xgrid} package to provide a simple interface to this distributed computing system \citep{ourpaper}. The package facilitates use of an Apple Xgrid for distributed processing of a job with many independent repetitions, by simplifying task submission (or {\em gridstuffing}) and collation of results. We demonstrate use of our package in the context of a real, although relatively simple, statistical problem. 

\section{One-sample t-test}

The t-test is remarkedly robust to violations of its 
underlying assumptions \citep{sawi:blai:1992}.
However, as \citet{Hesterberg} argues, not only is it possible for the total non-coverage to exceed $\alpha$, 
% while the one sample t-test maintains an appropriate Type-I error rate when the underlying data are skewed,
the asymmetry of the test statistic causes one tail to account for more than
its share of the overall $\alpha$ level. Hesterberg found that sample
sizes in the thousands were needed to get symmetric tails.

In this example, we demonstrate how to utilize an Apple Xgrid cluster to investigate the robustness of the one-sample t-test, by looking at how the $\alpha$ level is split between the two tails. When the number of simulations is small ($< 100,000$), this study runs very quickly as a loop in R. However here we provide a study consisting of $10^6$ simulations, and compare the results and computation time to the same study run on a local machine. 


\section{Using the Grid for a Simulation Study}

\subsection{Directory Structure}

Our first step is to set up an appropriate directory structure for our simulation (Figure~\ref{fig:directorystructure}). 

\begin{figure}[h!]
\centering
\includegraphics[width=0.5\textwidth]{directorystructure2.pdf}
\caption{File structure to access the grid}
\label{fig:directorystructure}
\end{figure}

The first item is the directory \file{input}, which contains two files that will
be run on the remote agents. The first of these files, \file{job.R}, defines 
the code to run a particular job (Figure \ref{code:job.R}). 

% paper is master copy of code; code in files should match code below. 
\begin{figure}[h!]
<<definejob>>=
# Assess the robustness of the one-sample 
# t-test when underlying data are exponential
# this function returns a dataframe with 
# number of rows equal to the value of "ntask"
# the option "param" specifies the sample size
job = function(ntask, param) {
   alpha = 0.05	 # how often to reject under null
   leftreject = logical(ntask)   # placeholder
   rightreject = logical(ntask)  # for results
   for (i in 1:ntask) {
      dat = rexp(param)   # generate skewed data
      left = t.test(dat, mu = 1, 
         alternative="less")   
      leftreject[i] = left$p.value <= alpha/2
      right = t.test(dat, mu=1, 
         alternative = "greater")
      rightreject[i] = right$p.value <= alpha/2
   }
   return(data.frame(leftreject, rightreject, 
      n=rep(param, ntask)))
}
@
\caption{Contents of \file{job.R}}
\label{code:job.R}
\end{figure}

For this example, the {\tt job()} function begins by generating a sample of {\tt param} exponential random variables with mean 1. A one-sample t-test is conducted on this sample, and logical ({\tt TRUE/FALSE}) values denoting whether the test rejected in that tail are saved in the vectors {\tt leftreject} and {\tt rightreject}. This process is repeated {\tt ntask} times, after which the function {\tt job()} returns a data frame with the rejection results and the corresponding sample size. 

The folder \file{input} also contains \file{runjob.R}, which retrieves 
and stores command line arguments from the controller, and passes them to 
{\tt job()} (Figure \ref{code:runjob.R}). The results from the completed job are saved as {\tt res0}, which is 
subsequently saved to the \file{output} folder. 

\begin{figure}[h!]
<<runjobR, eval=F>>=
source("job.R")
# processargs expects three arguments:
# 1) number of tasks to run within this job
# 2) parameter to pass to the function
# 3) place to stash the results when finished
processargs = function() {
   args = commandArgs(trailingOnly=TRUE)
   return(list(ntask=as.numeric(args[1]),
      param=args[2], resfile=args[3]))
}
arg = processargs()
res0 = job(arg$ntask, param=arg$param)
# stash the results
saveRDS(res0, file=arg$resfile)
@
\caption{Contents of \file{runjob.R}}
\label{code:runjob.R}
\end{figure}

The folder \file{input} may also contain other files needed for the simulation. In this example, no additional files are needed.
  
The next item in the directory structure is the folder \file{output}, which will contain results from the simulations. If it doesn't exist, the {\bf xgrid} package will create it. The \file{output} directory has a complete listing of the individual results as well as the R output from the remote agents.  This can be useful for debugging in case of problems.

The final item in the directory structure is \file{simulation.R}, which contains an R script to be run on the client machine that calls {\tt xgrid()} (Figure \ref{code:simulation.R}). This function submits the simulations to the grid for calculation. Results from all jobs are returned as one object, {\tt res}. The call to {\tt with()} summarizes all results in a table and prints them to the console.

\begin{figure}[h!]
<<simulation, eval=F>>=
library(xgrid)
# run the simulation 
res = xgrid(grid="Burton-303-iMac", Rcmd="runjob.R", param=30, 
   numsim=10^6, ntask=5*10^4) 
# analyze the results
with(res, table(leftreject,rightreject))
@
\caption{Contents of \file{simulation.R}}
\label{code:simulation.R}
\end{figure}

Here we specify a total of $10^6$ simulations, to be split into 20 jobs of $5 \times 10^4$ simulations each. Note that the number of jobs is calculated as the total number of simulations ({\tt numsim}) divided by the number of tasks per job ({\tt ntask}). Each simulation has a sample size of {\tt param}. 

Jobs are submitted to the grid by running \file{simulation.R}. Because this script is just an example of how to call {\tt xgrid()} and manipulate the resulting object, it can be run the way one typically submits commands during an R session. After the completion of each job, the results are saved to a file in the \file{output} directory. 

\subsection{Retrieval and Analysis of Results}
Figure \ref{code:expectedOutput} is an example of what to expect before and after completing all simulations. 

\begin{figure}[h!]
<<listingResults>>=
list.files()
list.files("input")
library(xgrid)
res = xgrid(grid="Burton-303-iMac", Rcmd="runjob.R", param=30, 
   numsim=10^6, ntask=5*10^4)
dim(res)
with(res, table(leftreject, rightreject))
list.files()
list.files("output")
@
\caption{Expected console output, before and after calling {\tt xgrid()}}
\label{code:expectedOutput}
\end{figure}

At the beginning of Figure \ref{code:expectedOutput}, we see the expected directory structure. We then call {\tt xgrid()} to send {\tt numsim=10\textasciicircum6} simulations to the grid for calculation. After the completion of the entire simulation study, results from all {\tt numsim} simulations are collated and returned by the {\tt xgrid()} function as the object {\tt res}. This object is also saved as the file \file{RESULTS.rda} at the top of the directory structure. 

Figure \ref{code:expectedOutput} also displays an example of what would be seen in the \file{output} folder. As expected, there are ten files of the form \file{RESULT-1000\#}, which contain the results from each individual job. The second set of ten files (e.g. \file{runjob.RRESULT-1000\#.Rout}) contain the code that was run to generate the corresponding result file. 

In this example, {\tt res} is a data frame with {\tt numsim} rows (one row for each simulation) and three columns (as defined in the {\tt return} statement of \file{job.R}). In Figure \ref{code:expectedOutput}, we list the dimensions of {\tt res} and summarize the results using {\tt with()}. 

In terms of our motivating example, when the underlying data are normally distributed, we could expect to reject the null hypothesis 2.5\% of the time on the left and 2.5\% on the right. The simulation yielded rejection rates of 6.5\% and 0.7\% for the left and right, respectively. This confirms Hesterberg's argument regarding lack of robustness for both the overall $\alpha$ level as well as the individual tails. As for computation time, this simulation took 48.2 seconds (standard deviation of 0.675) when run on a heterogeneous mixture of 20 iMacs and Mac Pros. When run locally on a single Quad-Core Intel Xeon Mac Pro computer, this simulation took 592 seconds (standard deviation of 0.365). 

\section{Acknowledgements} 

This material is based in part upon work supported by the National Institute of Mental Health (5R01MH087786-02) and the US National Science Foundation (DUE-0920350, DMS-0721661, and DMS-0602110).

\begin{thebibliography}{4}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Apple(2009)]{AppleXgridSystem}
Apple.
\newblock \emph{Mac OS X Server: Xgrid Administration and High Performance
  Computing (Version 10.6 Snow Leopard)}.
\newblock Apple Inc, 2009.

\bibitem[Hesterberg(2008)]{Hesterberg}
T.~Hesterberg.
\newblock It's time to retire the $n\geq30$ rule.
\newblock \emph{Proceedings of the Joint Statistical Meetings}, 2008.
\newblock \url{http://home.comcast.net/~timhesterberg/articles/}.

\bibitem[Horton et~al.(2011)Horton, Anoke, Zhao, and Jaeger]{ourpaper}
N.~J. Horton, S.~C. Anoke, Y.~Zhao, and H.~Jaeger.
\newblock Xgrid and {R}: Parallel distributed processing using heterogeneous
  groups of {A}pple computers.
\newblock \emph{In revision}, 2011.

\bibitem[Sawiloswky and Blair(1992)]{sawi:blai:1992}
S.~S. Sawiloswky and R.~C. Blair.
\newblock A more realistic look at the robustness and {Type II} error
  properties of the t test to departures from population normality.
\newblock \emph{Psychological Bulletin}, 111\penalty0 (2):\penalty0 352--360,
  1992.

\end{thebibliography}

\nonfrenchspacing

\end{document} 